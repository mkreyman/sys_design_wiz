# SysDesignWiz Architecture

## Overview

SysDesignWiz is an AI agent that plays the **interviewee/candidate** role in systems design interviews. The user acts as the interviewer, and the agent demonstrates good interview behavior: asking clarifying questions, giving concise casual answers, and generating architecture diagrams using Mermaid.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser (LiveView)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    Chat Panel       â”‚              Diagram Panel                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Messages      â”‚  â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚ - User        â”‚  â”‚  â”‚         Mermaid Diagram                 â”‚  â”‚
â”‚  â”‚ - Candidate   â”‚  â”‚  â”‚         (auto-updates)                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚                                         â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ Input (text)  â”‚  â”‚                                               â”‚
â”‚  â”‚ [ğŸ¤] Voice    â”‚  â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Tech Stack

- **Phoenix 1.7 / LiveView** - Real-time web interface
- **Claude Code SDK** - LLM integration (via OpenAI-compatible client)
- **Mermaid.js** - Diagram rendering (client-side)
- **Web Speech API** - Voice input (client-side)
- **Tailwind CSS** - Styling

## Module Structure

```
lib/sys_design_wiz/
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ conversation_agent.ex    # GenServer - conversation state
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ client_behaviour.ex      # Behaviour for LLM clients
â”‚   â””â”€â”€ openai_client.ex         # OpenAI API client
â”œâ”€â”€ context/
â”‚   â””â”€â”€ simple_memory.ex         # In-memory message history
â”œâ”€â”€ diagram/
â”‚   â”œâ”€â”€ mermaid_parser.ex        # Extract mermaid from responses
â”‚   â””â”€â”€ mermaid_sanitizer.ex     # Fix common syntax errors
â””â”€â”€ interview/
    â””â”€â”€ system_prompt.ex         # Candidate persona prompt

lib/sys_design_wiz_web/
â”œâ”€â”€ live/
â”‚   â””â”€â”€ chat_live.ex             # Main interview interface
â””â”€â”€ components/
    â””â”€â”€ core_components.ex       # Shared UI components

assets/js/
â”œâ”€â”€ app.js                       # Main JS entry
â””â”€â”€ hooks/
    â”œâ”€â”€ mermaid_hook.js          # Diagram rendering
    â”œâ”€â”€ voice_input_hook.js      # Web Speech API
    â””â”€â”€ scroll_hook.js           # Auto-scroll chat
```

## Data Flow

### 1. User Sends Message (Text)

```
User Input â†’ LiveView â†’ ConversationAgent.chat/2 â†’ OpenAI API
                                    â†“
                              Response with potential Mermaid
                                    â†“
                           MermaidParser.extract/1
                                    â†“
                    LiveView assigns: messages + diagram_code
                                    â†“
                         Browser renders both panels
```

### 2. User Sends Message (Voice)

```
Voice Input â†’ Web Speech API â†’ transcript â†’ LiveView event
                                    â†“
                           (same as text flow)
```

### 3. Diagram Auto-Update

```
Each assistant response â†’ MermaidParser.extract/1
                                    â†“
                    If diagram found: update @diagram_code
                                    â†“
                    MermaidHook re-renders diagram
```

## Key Components

### ConversationAgent (GenServer)

Manages conversation state per session:
- System prompt (candidate persona)
- Message history (SimpleMemory)
- LLM client reference

```elixir
%State{
  memory: %SimpleMemory{},
  llm_client: SysDesignWiz.LLM.OpenAIClient,
  tools: []  # No tools needed for this agent
}
```

### System Prompt (Candidate Persona)

Defines the agent's behavior:
- Ask 2-4 clarifying questions before designing
- Respond in short, casual paragraphs
- Generate Mermaid diagrams when discussing architecture
- Reference technologies from user preferences

### MermaidParser

Extracts Mermaid code blocks from LLM responses:

```elixir
def extract(response) do
  # Look for ```mermaid ... ``` blocks
  # Return {:ok, diagram_code} or :no_diagram
end
```

### MermaidSanitizer

Fixes common LLM mistakes in Mermaid syntax:
- Escape special characters in labels
- Fix node IDs with spaces
- Add missing direction declarations
- Balance unclosed subgraphs

### ChatLive (LiveView)

Two-panel layout with:
- Left: Chat messages + input (text/voice)
- Right: Mermaid diagram (auto-updating)
- Optional: Tech preference panel (collapsible)

Assigns:
```elixir
%{
  messages: [],
  input_value: "",
  loading: false,
  diagram_code: nil,
  tech_preferences: %{},
  voice_active: false
}
```

## JavaScript Hooks

### MermaidHook

```javascript
// Renders Mermaid diagram when @diagram_code changes
Hooks.Mermaid = {
  mounted() { this.render(); },
  updated() { this.render(); },
  render() {
    const code = this.el.dataset.code;
    if (code) mermaid.render('diagram', code, this.el);
  }
}
```

### VoiceInputHook

```javascript
// Web Speech API integration
Hooks.VoiceInput = {
  mounted() {
    this.recognition = new webkitSpeechRecognition();
    this.recognition.continuous = true;
    this.recognition.interimResults = true;
    // ... event handlers push to LiveView
  }
}
```

## Configuration

### Environment Variables

```bash
OPENAI_API_KEY=sk-...  # Required for LLM
```

### Application Config

```elixir
# config/config.exs
config :sys_design_wiz, :llm_client, SysDesignWiz.LLM.OpenAIClient

# config/test.exs
config :sys_design_wiz, :llm_client, SysDesignWiz.LLM.MockClient
```

## Testing Strategy

1. **Unit Tests**: MermaidParser, MermaidSanitizer, SystemPrompt
2. **Agent Tests**: ConversationAgent with mocked LLM client
3. **LiveView Tests**: ChatLive with mocked agent
4. **Integration**: Full flow with stubbed LLM responses

## Security Considerations

- XSS protection via HtmlSanitizeEx for markdown
- Mermaid code sanitized before rendering
- No user data persistence (in-memory only)
- Voice input stays client-side (Web Speech API)
